{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e559d15b",
      "metadata": {},
      "source": [
        "# AQI Estimation Model (Colab)\n",
        "\n",
        "This notebook builds a full AQI estimation pipeline:\n",
        "1. Load & preprocess raw OpenAQ-like data\n",
        "2. Aggregate/pivot to wide format + compute deterministic AQI labels\n",
        "3. Feature engineering for estimation (no location/city leakage)\n",
        "4. Train/compare models, select best, export artifacts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49a576bd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Clone repo (Colab) ===\n",
        "!git clone https://github.com/AshVenn/openaq-aqi-predictor.git\n",
        "%cd openaq-aqi-predictor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4126a79",
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Setup ===\n",
        "from pathlib import Path\n",
        "import json\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import GradientBoostingRegressor, HistGradientBoostingRegressor, RandomForestRegressor\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
        "from sklearn.pipeline import Pipeline\n",
        "import joblib\n",
        "\n",
        "# Project root (works when notebook is run from notebooks/)\n",
        "ROOT = Path.cwd()\n",
        "sys.path.insert(0, str(ROOT))\n",
        "\n",
        "from src import preprocessing\n",
        "from src.aqi import compute_aqi_dataframe\n",
        "from src.evaluate import regression_metrics\n",
        "from src.features import add_time_features\n",
        "\n",
        "INPUT_POLLUTANTS = [\"pm25\", \"pm10\", \"no2\", \"o3\", \"co\", \"so2\"]\n",
        "SIMULATE_MISSINGNESS = True\n",
        "MISSING_PROB = 0.2\n",
        "RANDOM_SEED = 42\n",
        "TRAIN_FREQ = \"D\"\n",
        "TEST_SIZE = 0.2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5afd4aab",
      "metadata": {},
      "source": [
        "## 1) Load & preprocess raw data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17cca583",
      "metadata": {},
      "outputs": [],
      "source": [
        "raw_path = ROOT / \"data\" / \"openaq.csv\"\n",
        "\n",
        "raw_df = preprocessing.load_raw_data(str(raw_path))\n",
        "clean_df = preprocessing.clean_raw_data(raw_df)\n",
        "\n",
        "print(f\"Raw rows: {len(raw_df):,}\")\n",
        "print(f\"Clean rows: {len(clean_df):,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91055b4a",
      "metadata": {},
      "source": [
        "## 2) Aggregate/pivot + compute deterministic AQI label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df182d87",
      "metadata": {},
      "outputs": [],
      "source": [
        "wide_df = preprocessing.aggregate_and_pivot(clean_df, freq=TRAIN_FREQ)\n",
        "\n",
        "# Compute deterministic AQI label (US EPA breakpoints)\n",
        "aqi_df = compute_aqi_dataframe(wide_df)\n",
        "\n",
        "# Persist processed datasets\n",
        "processed_wide_path = ROOT / \"data\" / \"processed_wide.csv\"\n",
        "processed_aqi_path = ROOT / \"data\" / \"processed_aqi.csv\"\n",
        "wide_df.to_csv(processed_wide_path, index=False)\n",
        "aqi_df.to_csv(processed_aqi_path, index=False)\n",
        "\n",
        "print(f\"Saved: {processed_wide_path}\")\n",
        "print(f\"Saved: {processed_aqi_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fd1a2d4",
      "metadata": {},
      "source": [
        "## 3) Feature engineering for AQI estimation (no leakage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "362c173f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def ensure_pollutant_columns(df, pollutant_cols):\n",
        "    df = df.copy()\n",
        "    for p in pollutant_cols:\n",
        "        if p not in df.columns:\n",
        "            df[p] = np.nan\n",
        "    return df\n",
        "\n",
        "\n",
        "def simulate_missingness(df, pollutant_cols, missing_prob, random_seed):\n",
        "    df = df.copy()\n",
        "    rng = np.random.default_rng(random_seed)\n",
        "    original = df[pollutant_cols].copy()\n",
        "    mask = rng.random(original.shape) < missing_prob\n",
        "    mask = mask & original.notna().values\n",
        "    df[pollutant_cols] = original.mask(mask)\n",
        "\n",
        "    # Ensure at least one pollutant remains per row if any were originally present\n",
        "    all_missing = df[pollutant_cols].isna().all(axis=1)\n",
        "    for idx in df.index[all_missing]:\n",
        "        available = original.loc[idx].dropna()\n",
        "        if not available.empty:\n",
        "            restore_col = rng.choice(available.index)\n",
        "            df.at[idx, restore_col] = original.at[idx, restore_col]\n",
        "    return df\n",
        "\n",
        "\n",
        "def add_missingness_indicators(df, pollutant_cols):\n",
        "    df = df.copy()\n",
        "    for p in pollutant_cols:\n",
        "        df[f\"{p}_is_missing\"] = df[p].isna().astype(int)\n",
        "    return df\n",
        "\n",
        "\n",
        "features_df = ensure_pollutant_columns(aqi_df, INPUT_POLLUTANTS)\n",
        "features_df = add_time_features(features_df, time_col=\"timestamp\")\n",
        "\n",
        "# Drop rows without AQI labels\n",
        "features_df = features_df[features_df[\"aqi\"].notna()].copy()\n",
        "\n",
        "if SIMULATE_MISSINGNESS:\n",
        "    features_df = simulate_missingness(\n",
        "        features_df,\n",
        "        INPUT_POLLUTANTS,\n",
        "        missing_prob=MISSING_PROB,\n",
        "        random_seed=RANDOM_SEED,\n",
        "    )\n",
        "\n",
        "features_df = add_missingness_indicators(features_df, INPUT_POLLUTANTS)\n",
        "\n",
        "feature_cols = (\n",
        "    [\"latitude\", \"longitude\", \"hour\", \"day_of_week\", \"month\"]\n",
        "    + INPUT_POLLUTANTS\n",
        "    + [f\"{p}_is_missing\" for p in INPUT_POLLUTANTS]\n",
        ")\n",
        "\n",
        "print(\"Feature columns:\")\n",
        "print(feature_cols)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88228bba",
      "metadata": {},
      "source": [
        "## 4) Train, compare, select best model, export artifacts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16846d8e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def time_split(df, time_col=\"timestamp\", test_size=0.2):\n",
        "    df = df.sort_values(time_col)\n",
        "    split_idx = int(len(df) * (1 - test_size))\n",
        "    return df.iloc[:split_idx].copy(), df.iloc[split_idx:].copy()\n",
        "\n",
        "\n",
        "def build_pipeline(estimator):\n",
        "    return Pipeline(\n",
        "        steps=[\n",
        "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "            (\"model\", estimator),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "\n",
        "train_df, test_df = time_split(features_df, test_size=TEST_SIZE)\n",
        "\n",
        "X_train = train_df[feature_cols]\n",
        "y_train = train_df[\"aqi\"]\n",
        "X_test = test_df[feature_cols]\n",
        "y_test = test_df[\"aqi\"]\n",
        "\n",
        "model_specs = {\n",
        "    \"LinearRegression\": {\n",
        "        \"estimator\": LinearRegression(),\n",
        "        \"param_grid\": None,\n",
        "    },\n",
        "    \"Ridge\": {\n",
        "        \"estimator\": Ridge(random_state=RANDOM_SEED),\n",
        "        \"param_grid\": {\"model__alpha\": [0.1, 1.0, 10.0, 50.0]},\n",
        "    },\n",
        "    \"Lasso\": {\n",
        "        \"estimator\": Lasso(random_state=RANDOM_SEED, max_iter=5000),\n",
        "        \"param_grid\": {\"model__alpha\": [0.001, 0.01, 0.1, 1.0]},\n",
        "    },\n",
        "    \"RandomForest\": {\n",
        "        \"estimator\": RandomForestRegressor(random_state=RANDOM_SEED, n_jobs=-1),\n",
        "        \"param_grid\": {\n",
        "            \"model__n_estimators\": [200, 400],\n",
        "            \"model__max_depth\": [None, 10, 20],\n",
        "            \"model__min_samples_split\": [2, 5],\n",
        "            \"model__min_samples_leaf\": [1, 2],\n",
        "        },\n",
        "    },\n",
        "    \"GradientBoosting\": {\n",
        "        \"estimator\": GradientBoostingRegressor(random_state=RANDOM_SEED),\n",
        "        \"param_grid\": {\n",
        "            \"model__n_estimators\": [100, 200],\n",
        "            \"model__learning_rate\": [0.05, 0.1],\n",
        "            \"model__max_depth\": [2, 3],\n",
        "        },\n",
        "    },\n",
        "    \"HistGradientBoosting\": {\n",
        "        \"estimator\": HistGradientBoostingRegressor(random_state=RANDOM_SEED),\n",
        "        \"param_grid\": {\n",
        "            \"model__max_depth\": [3, 6, None],\n",
        "            \"model__learning_rate\": [0.05, 0.1],\n",
        "            \"model__max_iter\": [200, 400],\n",
        "        },\n",
        "    },\n",
        "}\n",
        "\n",
        "results = []\n",
        "best_models = {}\n",
        "cv = TimeSeriesSplit(n_splits=3)\n",
        "\n",
        "for name, spec in model_specs.items():\n",
        "    pipeline = build_pipeline(spec[\"estimator\"])\n",
        "    if spec[\"param_grid\"]:\n",
        "        grid = GridSearchCV(\n",
        "            pipeline,\n",
        "            param_grid=spec[\"param_grid\"],\n",
        "            cv=cv,\n",
        "            scoring=\"neg_mean_absolute_error\",\n",
        "            n_jobs=-1,\n",
        "        )\n",
        "        grid.fit(X_train, y_train)\n",
        "        best_estimator = grid.best_estimator_\n",
        "        best_params = grid.best_params_\n",
        "    else:\n",
        "        best_estimator = pipeline.fit(X_train, y_train)\n",
        "        best_params = None\n",
        "\n",
        "    preds = best_estimator.predict(X_test)\n",
        "    metrics = regression_metrics(y_test, preds)\n",
        "\n",
        "    results.append(\n",
        "        {\n",
        "            \"model\": name,\n",
        "            \"mae\": metrics[\"mae\"],\n",
        "            \"rmse\": metrics[\"rmse\"],\n",
        "            \"r2\": metrics[\"r2\"],\n",
        "            \"best_params\": best_params,\n",
        "        }\n",
        "    )\n",
        "    best_models[name] = best_estimator\n",
        "\n",
        "results_df = pd.DataFrame(results).sort_values([\"mae\", \"rmse\"]).reset_index(drop=True)\n",
        "results_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eaba0489",
      "metadata": {},
      "outputs": [],
      "source": [
        "best_row = results_df.iloc[0]\n",
        "best_model_name = best_row[\"model\"]\n",
        "print(f\"Best model: {best_model_name}\")\n",
        "\n",
        "# Refit best model on full dataset for export\n",
        "best_spec = model_specs[best_model_name]\n",
        "best_pipeline = build_pipeline(best_spec[\"estimator\"])\n",
        "if best_row[\"best_params\"]:\n",
        "    best_pipeline.set_params(**best_row[\"best_params\"])\n",
        "\n",
        "X_full = features_df[feature_cols]\n",
        "y_full = features_df[\"aqi\"]\n",
        "best_pipeline.fit(X_full, y_full)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83199335",
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Export artifacts ===\n",
        "models_dir = ROOT / \"models\"\n",
        "models_dir.mkdir(exist_ok=True)\n",
        "\n",
        "model_path = models_dir / \"aqi_estimator.joblib\"\n",
        "feature_cols_path = models_dir / \"feature_cols.json\"\n",
        "model_meta_path = models_dir / \"model_meta.json\"\n",
        "\n",
        "joblib.dump(best_pipeline, model_path)\n",
        "\n",
        "with open(feature_cols_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(feature_cols, f, indent=2)\n",
        "\n",
        "model_meta = {\n",
        "    \"best_model_name\": best_model_name,\n",
        "    \"input_pollutants\": INPUT_POLLUTANTS,\n",
        "    \"features\": feature_cols,\n",
        "    \"uses_missingness_indicators\": True,\n",
        "    \"time_features\": [\"hour\", \"day_of_week\", \"month\"],\n",
        "    \"expects_standard_units\": True,\n",
        "    \"trained_freq\": TRAIN_FREQ,\n",
        "    \"missingness_simulated\": SIMULATE_MISSINGNESS,\n",
        "    \"missing_prob\": MISSING_PROB if SIMULATE_MISSINGNESS else None,\n",
        "}\n",
        "\n",
        "with open(model_meta_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(model_meta, f, indent=2)\n",
        "\n",
        "print(f\"Saved model: {model_path}\")\n",
        "print(f\"Saved feature columns: {feature_cols_path}\")\n",
        "print(f\"Saved metadata: {model_meta_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c2b3a67",
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Write report summary ===\n",
        "reports_path = ROOT / \"reports\" / \"summary.md\"\n",
        "\n",
        "summary_lines = [\n",
        "    \"# AQI Estimation Model Summary\",\n",
        "    \"\",\n",
        "    \"## Dataset\",\n",
        "    f\"- Rows after cleaning: {len(clean_df):,}\",\n",
        "    f\"- Rows after aggregation: {len(wide_df):,}\",\n",
        "    f\"- Rows with AQI labels: {len(features_df):,}\",\n",
        "    f\"- Aggregation window: {TRAIN_FREQ}\",\n",
        "    \"\",\n",
        "    \"## Model Comparison (test set)\",\n",
        "    results_df.to_markdown(index=False),\n",
        "    \"\",\n",
        "    \"## Best Model\",\n",
        "    f\"- {best_model_name}\",\n",
        "    f\"- MAE: {best_row['mae']:.2f}\",\n",
        "    f\"- RMSE: {best_row['rmse']:.2f}\",\n",
        "    f\"- R2: {best_row['r2']:.3f}\",\n",
        "]\n",
        "\n",
        "reports_path.write_text(\"\n",
        "\".join(summary_lines), encoding=\"utf-8\")\n",
        "print(f\"Wrote report: {reports_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
